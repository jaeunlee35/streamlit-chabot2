import streamlit as st
from langchain_core.messages import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_teddynote.models import MultiModal
import os


# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")
if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

st.set_page_config(page_title="ì´ë¯¸ì§€ ì¸ì‹ ê¸°ë°˜ ì±—ë´‡ ğŸ’¬", page_icon="ğŸ’¬", layout="wide")
st.title("ì´ë¯¸ì§€ ì¸ì‹ ê¸°ë°˜ ì±—ë´‡ ğŸ’¬")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

main1, main2 = st.tabs(["ì´ë¯¸ì§€", "ëŒ€í™”ë‚´ìš©"])


def print_history():
    for msg in st.session_state["messages"]:
        main2.chat_message(msg.role).write(msg.content)


def add_history(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))


@st.cache_resource(show_spinner="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ì¤‘ì…ë‹ˆë‹¤...")
def image_processing(file):
    # ì—…ë¡œë“œí•œ íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    file_content = file.read()
    file_path = f"./.cache/files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)

    return file_path


# ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
def create_chain(image_filepath, system_prompt, user_prompt, model_name="gpt-4o"):
    llm = ChatOpenAI(model=model_name, temperature=0)

    # ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„±
    multimodal = MultiModal(llm, system_prompt=system_prompt, user_prompt=user_prompt)

    # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë¶€í„° ì§ˆì˜(ìŠ¤íŠ¸ë¦¼ ë°©ì‹)
    answer = multimodal.stream(image_filepath)
    return answer


with st.sidebar:
    clear_btn = st.button("ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™”")
    # LLM ì„ íƒ
    model_selection = st.selectbox("LLM ì„ íƒ", ["gpt-4o", "gpt-4o-mini"])

    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    file = st.file_uploader(
        "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        type=["jpg", "jpeg", "png"],
    )

    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
        "ë‹¹ì‹ ì€ í‘œ(ì¬ë¬´ì œí‘œ) ë¥¼ í•´ì„í•˜ëŠ” ê¸ˆìœµ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ í…Œì´ë¸” í˜•ì‹ì˜ ì¬ë¬´ì œí‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤ì„ ì •ë¦¬í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.",
        height=200,
    )

if clear_btn:
    st.session_state["messages"].clear()

print_history()


if file:
    image_filepath = image_processing(file)
    main1.image(image_filepath, use_column_width=True)

msg_container = main2.empty()

if user_input := st.chat_input():
    # ì´ë¯¸ì§€ íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ê²½ìš°
    if file:
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image_filepath = image_processing(file)
        # ë©€í‹°ëª¨ë‹¬ ì²´ì¸ì— ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ìš”ì²­
        answer = create_chain(
            image_filepath, system_prompt, user_input, model_name=model_selection
        )

        main2.chat_message("user").write(user_input)

        # ìš”ì²­ì‚¬í•­ì„ ì²˜ë¦¬
        with main2.chat_message("assistant"):
            chat_container = st.empty()
            ai_answer = ""
            for chunk in answer:
                ai_answer += chunk.content
                chat_container.markdown(ai_answer)

        add_history("user", user_input)
        add_history("ai", ai_answer)
    else:
        msg_container.error("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
